# Cross-Modal Multimedia Retrieval for Image Search Engines

## Abstract
In this paper, we investigated different approaches to build a 
large-scale image search engine. Given a natural language query, 
the task involves searching for relevant images. The fundamental 
problem in this challenge boils down to bridging the textual and 
image representation of the same entity or scene. To this end, we 
combined image features extracted from intermediate layers in a 
pre-trained Residual Network (ResNet) and text descriptions of the 
images to train our models. We experimented with multilayer perceptrons 
and partial least square regressions and proposed a meta model that 
combines the output of several models. This approach proved successful 
when compared to the rest of submissions in the Kaggle leaderboard.
